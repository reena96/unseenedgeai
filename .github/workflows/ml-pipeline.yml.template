# GitHub Actions CI/CD Pipeline for UnseenEdge AI ML System
#
# This workflow provides automated testing, model training, and deployment.
# To use this template:
# 1. Copy to .github/workflows/ml-pipeline.yml
# 2. Update the environment variables and secrets
# 3. Customize the triggers and jobs as needed
#
# Required GitHub Secrets:
# - GCP_PROJECT_ID: Your GCP project ID
# - GCP_SA_KEY: Service account JSON key (base64 encoded)
# - OPENAI_API_KEY: OpenAI API key for GPT-4o-mini
# - DATABASE_URL: Production database URL
# - SECRET_KEY: JWT secret key

name: ML Pipeline

on:
  # Run on pull requests
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'backend/**'
      - '.github/workflows/**'

  # Run on pushes to main
  push:
    branches:
      - main
    paths:
      - 'backend/**'

  # Run weekly to retrain models
  schedule:
    - cron: '0 0 * * 0'  # Every Sunday at midnight UTC

  # Allow manual triggers
  workflow_dispatch:
    inputs:
      generate_data:
        description: 'Generate new synthetic data'
        required: false
        type: boolean
        default: false
      num_samples:
        description: 'Number of samples to generate'
        required: false
        default: '1000'
      deploy_to_production:
        description: 'Deploy to production after tests pass'
        required: false
        type: boolean
        default: false

# ================================================================================
# ENVIRONMENT VARIABLES
# ================================================================================

env:
  PYTHON_VERSION: '3.10'
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-central1'
  SERVICE_NAME: 'skill-assessment'
  IMAGE_NAME: 'gcr.io/${{ secrets.GCP_PROJECT_ID }}/skill-assessment'

# ================================================================================
# JOBS
# ================================================================================

jobs:

  # ==============================================================================
  # JOB 1: CODE QUALITY & LINTING
  # ==============================================================================

  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install black flake8 mypy isort
          pip install -r requirements.txt

      - name: Run Black (formatting check)
        run: |
          cd backend
          black --check app/ tests/
        continue-on-error: false

      - name: Run isort (import sorting check)
        run: |
          cd backend
          isort --check-only app/ tests/
        continue-on-error: false

      - name: Run Flake8 (linting)
        run: |
          cd backend
          flake8 app/ tests/ --max-line-length=100 --ignore=E203,W503
        continue-on-error: false

      - name: Run MyPy (type checking)
        run: |
          cd backend
          mypy app/ --ignore-missing-imports
        continue-on-error: true  # Type checking is nice-to-have

  # ==============================================================================
  # JOB 2: UNIT & INTEGRATION TESTS
  # ==============================================================================

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint

    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio

      - name: Set up test environment variables
        run: |
          cd backend
          cat > .env <<EOF
          DATABASE_URL=postgresql://postgres:postgres@localhost:5432/testdb
          REDIS_URL=redis://localhost:6379/0
          SECRET_KEY=test-secret-key
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          ENVIRONMENT=test
          EOF

      - name: Run database migrations
        run: |
          cd backend
          alembic upgrade head

      - name: Run tests with coverage
        run: |
          cd backend
          pytest tests/ -v --cov=app --cov-report=xml --cov-report=term

      - name: Upload coverage to Codecov (optional)
        if: github.event_name == 'pull_request'
        uses: codecov/codecov-action@v3
        with:
          files: ./backend/coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Check coverage threshold
        run: |
          cd backend
          coverage report --fail-under=70

  # ==============================================================================
  # JOB 3: GENERATE SYNTHETIC DATA (Scheduled or Manual)
  # ==============================================================================

  generate-data:
    name: Generate Synthetic Data
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.generate_data == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate synthetic data
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          cd backend
          NUM_SAMPLES=${{ github.event.inputs.num_samples || '1000' }}

          python scripts/generate_training_data.py \
            --count $NUM_SAMPLES \
            --output data/training_data_$(date +%Y%m%d).csv

      - name: Upload data as artifact
        uses: actions/upload-artifact@v3
        with:
          name: synthetic-data-${{ github.run_number }}
          path: backend/data/training_data_*.csv
          retention-days: 30

  # ==============================================================================
  # JOB 4: TRAIN MODELS (Scheduled or Manual)
  # ==============================================================================

  train-models:
    name: Train ML Models
    runs-on: ubuntu-latest
    needs: generate-data
    if: github.event_name == 'schedule' || github.event.inputs.generate_data == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download training data
        uses: actions/download-artifact@v3
        with:
          name: synthetic-data-${{ github.run_number }}
          path: backend/data/

      - name: Train models
        run: |
          cd backend
          DATA_FILE=$(ls -t data/training_data_*.csv | head -1)

          python app/ml/train_models.py \
            --data-path $DATA_FILE \
            --models-dir models/v${{ github.run_number }} \
            --version v${{ github.run_number }}

      - name: Evaluate models
        run: |
          cd backend
          python app/ml/evaluate_models.py \
            --models-dir models/v${{ github.run_number }}

      - name: Upload models as artifact
        uses: actions/upload-artifact@v3
        with:
          name: trained-models-${{ github.run_number }}
          path: backend/models/v${{ github.run_number }}/
          retention-days: 90

      - name: Upload evaluation report
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-report-${{ github.run_number }}
          path: backend/evaluation_report.json
          retention-days: 90

  # ==============================================================================
  # JOB 5: BUILD & PUSH DOCKER IMAGE
  # ==============================================================================

  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event.inputs.deploy_to_production == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Configure Docker for GCR
        run: |
          gcloud auth configure-docker

      - name: Download latest trained models (if available)
        if: github.event_name == 'schedule'
        uses: actions/download-artifact@v3
        with:
          name: trained-models-${{ github.run_number }}
          path: backend/models/
        continue-on-error: true

      - name: Build Docker image
        run: |
          cd backend
          docker build -t ${{ env.IMAGE_NAME }}:${{ github.sha }} \
                       -t ${{ env.IMAGE_NAME }}:latest .

      - name: Push Docker image
        run: |
          docker push ${{ env.IMAGE_NAME }}:${{ github.sha }}
          docker push ${{ env.IMAGE_NAME }}:latest

      - name: Output image digest
        run: |
          echo "Image: ${{ env.IMAGE_NAME }}:${{ github.sha }}"

  # ==============================================================================
  # JOB 6: DEPLOY TO STAGING
  # ==============================================================================

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Deploy to Cloud Run (Staging)
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }}-staging \
            --image ${{ env.IMAGE_NAME }}:${{ github.sha }} \
            --platform managed \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }} \
            --set-env-vars "ENVIRONMENT=staging" \
            --allow-unauthenticated

      - name: Get staging URL
        id: staging-url
        run: |
          URL=$(gcloud run services describe ${{ env.SERVICE_NAME }}-staging \
            --platform managed \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }} \
            --format 'value(status.url)')

          echo "STAGING_URL=$URL" >> $GITHUB_OUTPUT
          echo "Staging URL: $URL"

      - name: Run smoke tests on staging
        run: |
          STAGING_URL="${{ steps.staging-url.outputs.STAGING_URL }}"

          # Health check
          curl -f $STAGING_URL/api/v1/health || exit 1

          # Detailed health
          curl -f $STAGING_URL/api/v1/health/detailed || exit 1

          echo "âœ… Staging deployment successful!"

      - name: Comment PR with staging URL
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ðŸš€ Deployed to staging: ${{ steps.staging-url.outputs.STAGING_URL }}`
            })

  # ==============================================================================
  # JOB 7: DEPLOY TO PRODUCTION (Manual Approval Required)
  # ==============================================================================

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event.inputs.deploy_to_production == 'true'
    environment:
      name: production
      url: https://skill-assessment-xyz.run.app

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Deploy to Cloud Run (Production)
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.IMAGE_NAME }}:${{ github.sha }} \
            --platform managed \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }} \
            --set-env-vars "ENVIRONMENT=production" \
            --allow-unauthenticated

      - name: Get production URL
        id: production-url
        run: |
          URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \
            --platform managed \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }} \
            --format 'value(status.url)')

          echo "PRODUCTION_URL=$URL" >> $GITHUB_OUTPUT
          echo "Production URL: $URL"

      - name: Run smoke tests on production
        run: |
          PRODUCTION_URL="${{ steps.production-url.outputs.PRODUCTION_URL }}"

          # Health check
          curl -f $PRODUCTION_URL/api/v1/health || exit 1

          echo "âœ… Production deployment successful!"

      - name: Notify Slack (optional)
        if: success()
        uses: slackapi/slack-github-action@v1
        with:
          webhook-url: ${{ secrets.SLACK_WEBHOOK_URL }}
          payload: |
            {
              "text": "ðŸš€ Production deployment successful!",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Production Deployment* ðŸš€\n\nImage: `${{ env.IMAGE_NAME }}:${{ github.sha }}`\nURL: ${{ steps.production-url.outputs.PRODUCTION_URL }}"
                  }
                }
              ]
            }
        continue-on-error: true

  # ==============================================================================
  # JOB 8: SECURITY SCAN (Optional)
  # ==============================================================================

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.IMAGE_NAME }}:${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

# ================================================================================
# SUMMARY
# ================================================================================

# This workflow provides:
# 1. âœ… Automated linting and formatting checks
# 2. âœ… Comprehensive testing with coverage reports
# 3. âœ… Scheduled synthetic data generation
# 4. âœ… Automated model training and evaluation
# 5. âœ… Docker image building and pushing to GCR
# 6. âœ… Staged deployments (staging â†’ production)
# 7. âœ… Smoke tests on deployments
# 8. âœ… Security scanning with Trivy
# 9. âœ… Slack notifications (optional)
# 10. âœ… PR comments with staging URLs
#
# To customize:
# - Adjust test coverage thresholds
# - Add more sophisticated smoke tests
# - Integrate with monitoring tools (Datadog, New Relic)
# - Add performance regression tests
# - Implement blue-green or canary deployments
